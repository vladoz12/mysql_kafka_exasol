[2021-08-23 22:21:46,807] INFO Initializing writer using SQL dialect: ExasolDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask)
[2021-08-23 22:21:46,807] INFO WorkerSinkTask{id=exasol-sink-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask)
[2021-08-23 22:21:46,812] INFO [Consumer clientId=connector-consumer-exasol-sink-0, groupId=connect-exasol-sink] Cluster ID: OPKOd0MRTOy2fwjE3PTdXw (org.apache.kafka.clients.Metadata)
[2021-08-23 22:21:46,819] INFO [Consumer clientId=connector-consumer-exasol-sink-0, groupId=connect-exasol-sink] Discovered group coordinator kafka03.internal:9094 (id: 2147483645 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[2021-08-23 22:21:46,824] INFO [Consumer clientId=connector-consumer-exasol-sink-0, groupId=connect-exasol-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[2021-08-23 22:21:49,846] INFO [Consumer clientId=connector-consumer-exasol-sink-0, groupId=connect-exasol-sink] Successfully joined group with generation Generation{generationId=15, memberId='connector-consumer-exasol-sink-0-de4f0a94-aad8-49bf-8bba-ee8ef28ecb7a', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[2021-08-23 22:21:49,846] INFO [Consumer clientId=connector-consumer-exasol-sink-0, groupId=connect-exasol-sink] Finished assignment for group at generation 15: {connector-consumer-exasol-sink-0-de4f0a94-aad8-49bf-8bba-ee8ef28ecb7a=Assignment(partitions=[new_timestamp_table-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2021-08-23 22:21:49,856] INFO [Consumer clientId=connector-consumer-exasol-sink-0, groupId=connect-exasol-sink] Successfully synced group in generation Generation{generationId=15, memberId='connector-consumer-exasol-sink-0-de4f0a94-aad8-49bf-8bba-ee8ef28ecb7a', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[2021-08-23 22:21:49,857] INFO [Consumer clientId=connector-consumer-exasol-sink-0, groupId=connect-exasol-sink] Notifying assignor about the new Assignment(partitions=[new_timestamp_table-0]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2021-08-23 22:21:49,858] INFO [Consumer clientId=connector-consumer-exasol-sink-0, groupId=connect-exasol-sink] Adding newly assigned partitions: new_timestamp_table-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2021-08-23 22:21:49,859] INFO [Consumer clientId=connector-consumer-exasol-sink-0, groupId=connect-exasol-sink] Found no committed offset for partition new_timestamp_table-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2021-08-23 22:21:49,862] INFO [Consumer clientId=connector-consumer-exasol-sink-0, groupId=connect-exasol-sink] Resetting offset for partition new_timestamp_table-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2021-08-23 22:21:49,988] ERROR WorkerSinkTask{id=exasol-sink-0} Task threw an uncaught and unrecoverable exception (org.apache.kafka.connect.runtime.WorkerTask)
org.apache.kafka.connect.errors.ConnectException: Tolerance exceeded in error handler
	at org.apache.kafka.connect.runtime.errors.RetryWithToleranceOperator.execAndHandleError(RetryWithToleranceOperator.java:206)
	at org.apache.kafka.connect.runtime.errors.RetryWithToleranceOperator.execute(RetryWithToleranceOperator.java:132)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.convertAndTransformRecord(WorkerSinkTask.java:498)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.convertMessages(WorkerSinkTask.java:475)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:325)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:229)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:235)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: org.apache.kafka.connect.errors.DataException: Invalid type for Timestamp, underlying representation should be integral but was STRING
	at io.confluent.connect.json.JsonSchemaData.lambda$static$15(JsonSchemaData.java:273)
	at io.confluent.connect.json.JsonSchemaData.toConnectData(JsonSchemaData.java:559)
	at io.confluent.connect.json.JsonSchemaData.toConnectSchema(JsonSchemaData.java:971)
	at io.confluent.connect.json.JsonSchemaData.toConnectSchema(JsonSchemaData.java:886)
	at io.confluent.connect.json.JsonSchemaData.toConnectSchema(JsonSchemaData.java:806)
	at io.confluent.connect.json.JsonSchemaData.toConnectSchema(JsonSchemaData.java:802)
	at io.confluent.connect.json.JsonSchemaData.toConnectSchema(JsonSchemaData.java:938)
	at io.confluent.connect.json.JsonSchemaData.toConnectSchema(JsonSchemaData.java:795)
	at io.confluent.connect.json.JsonSchemaConverter.toConnectData(JsonSchemaConverter.java:107)
	at org.apache.kafka.connect.storage.Converter.toConnectData(Converter.java:87)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.lambda$convertAndTransformRecord$1(WorkerSinkTask.java:498)
	at org.apache.kafka.connect.runtime.errors.RetryWithToleranceOperator.execAndRetry(RetryWithToleranceOperator.java:156)
	at org.apache.kafka.connect.runtime.errors.RetryWithToleranceOperator.execAndHandleError(RetryWithToleranceOperator.java:190)
	... 13 more
